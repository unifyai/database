sparseml:
  name: "SparseML"

  image_url: sparseml.png

  tags:
    - compression
    - pruning
    - distillation
    - quantization
    - pytorch
    - tensorflow
    - keras
    - open-source
    - apache-2.0

  temperature: hot
  url: https://github.com/neuralmagic/sparseml
  release: "2020-12-11"

  description: |
    SparseML is an open source library developed and maintained by
    [Neural Magic](https://neuralmagic.com/) for applying compression recipes to neural
    networks.

    Currently, it supports pruning, quantization and knowledge distillation for
    compressing Vision, NLP, and now, large language models as well. SparseML also
    provides pre-compressed and pre-quantized models in their SparseZoo.

  features:
    - "Gradual Magnitude Pruning (GMP)"
    - "Alternating Compressed/DeCompressed Pruning (AC/DC)"
    - "Optimal BERT Surgeon (oBERT)"
    - "Pre-Compressed models via SparseZoo"
    - "Knowledge Distillation Recipes"
