tpu:
  name: "tpu"

  image_url: tpu.jpg

  tags:
    - custom-hardware
    - hardware
    - mlir

  url: https://cloud.google.com/tpu/docs/intro-to-tpu

  description: |
    Google's Tensor Processing Units (TPUs) are custom-designed application-specific
    integrated circuits (ASICs) developed by Google specifically for accelerating
    machine learning workloads, particularly those that involve training and running
    deep neural networks. TPUs are optimized for matrix multiplication / linear algebra
    operations, which are fundamental to many deep learning algorithms. TPUs employ a
    systolic array architecture which is essentially just a large physical matrix.
    Software designed for TPUs necessitates compilation through the Accelerator Linear
    Algebra (XLA) compiler. XLA operates as a just-in-time compiler, processing the
    graph generated by an ML framework application and converting the linear algebra,
    loss, and gradient elements of the graph into TPU machine code.

  features:
    - "Tensor Processing."
    - "Optimized for training and inference."
